def tokeniser(string, depth):
    """
    string: a passage of text to split into markov chain token - result pairs
    depth: how many words/punctuation, should be in each token

    Returns a dict of token - result pairs, where a result of None
    denotes the end of a passage of text.
    """
    pass
